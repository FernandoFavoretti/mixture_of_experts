{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class Expert():\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    \n",
    "    def sigmoid_derivativa(self, x):\n",
    "        return self.sigmoid(x) * (1 - self.sigmoid(x))\n",
    "\n",
    "    \n",
    "    def tan_hiperbolica(self, x):\n",
    "        #from https://alexander-wong.com/post/neural-networks-and-deep-learning-week3/\n",
    "        return (np.exp(x) - np.exp(-x))/(np.exp(x) + np.exp(-x))\n",
    "\n",
    "    \n",
    "    def tan_hiperbolica_derivativa(self, x):\n",
    "        #from https://alexander-wong.com/post/neural-networks-and-deep-learning-week3/\n",
    "        return 1 - self.tan_hiperbolica(x)**2\n",
    "    \n",
    "    \n",
    "    def softmax(self,x):\n",
    "        e_x = np.exp(x - np.max(x))\n",
    "        return e_x / e_x.sum()\n",
    "    \n",
    "    \n",
    "    def softmax_derivativa(self,x):\n",
    "        '''\n",
    "        Retirada do codigo disponibilizado em aula ` dYdYin(:,cont)=(1-Y(:,i)).*Y(:,i);%sigmoid e softamax`\n",
    "        '''\n",
    "        return self.softmax(x) * (1 - self.softmax(x))\n",
    "    \n",
    "    \n",
    "    def __init__(self,ne,nh,ns,g_h,g_o):\n",
    "        '''\n",
    "        ne = numero de neuronios entradas\n",
    "        nh = numero neuronios hidden layer\n",
    "        ns = numero de neuronios saida\n",
    "        \n",
    "        As funcoes de ativacao sao denotadas por\n",
    "        g_h = funcao de ativacao camada escondida\n",
    "        g_o = funcao de ativacao camada de saida\n",
    "        \n",
    "        e podem receber as seguintes entradas\n",
    "        'sigmoid', 'tan_h', 'softmax' e 'linear'\n",
    "        '''\n",
    "        self.W1=np.random.uniform(size=(ne,nh))\n",
    "        self.b1=np.random.uniform(size=(1,nh))\n",
    "        self.W2=np.random.uniform(size=(nh,ns))\n",
    "        self.b2=np.random.uniform(size=(1,ns))\n",
    "        self.ghidden = g_h\n",
    "        self.gout = g_o\n",
    "        \n",
    "        \n",
    "    def executa_funcao_ativacao(self, tipo, x, derivativa=False):\n",
    "        if tipo == 'sigmoid':\n",
    "            if derivativa:\n",
    "                return self.sigmoid_derivativa(x)\n",
    "            else:\n",
    "                return self.sigmoid(x)\n",
    "        elif tipo == 'tan_h':\n",
    "            if derivativa:\n",
    "                return self.tan_hiperbolica_derivativa(x)\n",
    "            else:\n",
    "                return self.tan_hiperbolica(x)\n",
    "        elif tipo == 'softmax':\n",
    "            if derivativa:\n",
    "                return self.softmax_derivativa(x)\n",
    "            else:\n",
    "                return self.softmax(x)\n",
    "        elif tipo == 'linear':\n",
    "            if derivativa:\n",
    "                return np.ones(x.shape)\n",
    "            else:\n",
    "                return x\n",
    "    \n",
    "    \n",
    "    def calcula_loss(self,erro_epoca):\n",
    "        '''\n",
    "        Calcula EQM\n",
    "        '''\n",
    "        loss = np.square(erro_epoca).mean()\n",
    "        return loss\n",
    "            \n",
    "            \n",
    "    def feedforward(self, X):\n",
    "        #Forward Propogation\n",
    "        #entrada -> hidden\n",
    "        z1 = np.dot(X,self.W1) + self.b1\n",
    "        a1 = self.executa_funcao_ativacao(self.ghidden, z1)\n",
    "        #hidden -> saida\n",
    "        z2=np.dot(a1,self.W2)+ self.b2\n",
    "        output = self.executa_funcao_ativacao(self.gout, z2)\n",
    "        return z1,a1,z2,output\n",
    "    \n",
    "    \n",
    "    def backpropagation(self, X,y,z1,a1,z2,output):\n",
    "        #Calcula deltas por partes\n",
    "        erro_epoca = output - y\n",
    "        delta_output = self.executa_funcao_ativacao(self.gout, output, derivativa=True)\n",
    "        d_z2 = erro_epoca * delta_output\n",
    "        erro_hidden = d_z2.dot(self.W2.T) * (1/len(X))\n",
    "        delta_hidden = self.executa_funcao_ativacao(self.ghidden,z1,derivativa=True)\n",
    "        d_z1 = erro_hidden * delta_hidden * (1/len(X))\n",
    "        \n",
    "        #Atualiza pesos\n",
    "        self.W2 -= z1.T.dot(d_z2) * alpha\n",
    "        self.b2 -= np.sum(d_z2, axis=0,keepdims=True) * alpha\n",
    "        self.W1 -= X.T.dot(d_z1) * alpha\n",
    "        self.b1 -= np.sum(d_z1, axis=0,keepdims=True) * alpha\n",
    "        return erro_epoca\n",
    "    \n",
    "\n",
    "    def train(self, max_epoch, alpha, X, y, X_val, y_val, numero_max_erro_val, plot=False):\n",
    "        #Variaveis de controle\n",
    "        all_losses = [] #para plot\n",
    "        numero_erro_validacao_subiu = 0 #acompanhamento do erro de validacao\n",
    "        last_eqm_val = 99999  #acompanhamento do erro de validacao\n",
    "\n",
    "        #armazena melhores pesos para retorno posterior\n",
    "        melhores_pesos = {\n",
    "            'W1' : self.W1,\n",
    "            'b1' : self.b1,\n",
    "            'W2' : self.W2,\n",
    "            'b2' : self.b2\n",
    "        }\n",
    "        #Itera sobre as epocas\n",
    "        for epoch in range(1,max_epoch+1):\n",
    "            #feedforward\n",
    "            z1,a1,z2,output = self.feedforward(X)\n",
    "            #backward\n",
    "            erro_epoca = self.backpropagation(X,y,z1,a1,z2,output)\n",
    "            #gera loss\n",
    "            all_losses.append(self.calcula_loss(erro_epoca))\n",
    "            \n",
    "            #calculo para acompanhar erro no conjunto de validacao\n",
    "            z1_val,a1_val,z2_val,output_val = self.feedforward(X_val)\n",
    "            #calcula erro de validacao\n",
    "            erro_validacao = output_val - y_val\n",
    "            eqm_validacao = self.calcula_loss(erro_validacao)\n",
    "            \n",
    "            #Acompanhamento eveolucao do erro no conjunto de validacao\n",
    "            if eqm_validacao < last_eqm_val:\n",
    "                numero_erro_validacao_subiu = 0\n",
    "                last_eqm_val = eqm_validacao\n",
    "                #Atualiza melhores pesos\n",
    "                melhores_pesos = {\n",
    "                    'W1' : self.W1,\n",
    "                    'b1' : self.b1,\n",
    "                    'W2' : self.W2,\n",
    "                    'b2' : self.b2\n",
    "                }\n",
    "            else:\n",
    "                last_eqm_val = eqm_validacao\n",
    "                numero_erro_validacao_subiu += 1\n",
    "                if numero_erro_validacao_subiu >= numero_max_erro_val:\n",
    "                    print(\"Treinamento encerrado por aumentos consecutivos no erro de validacao, epocas {}\".format(epoch))\n",
    "                    #retorna os melhores pesos\n",
    "                    self.W1 = melhores_pesos['W1']\n",
    "                    self.b1 = melhores_pesos['b1']\n",
    "                    self.W2 = melhores_pesos['W2']\n",
    "                    self.b2 = melhores_pesos['b2']\n",
    "                    if plot:       \n",
    "                        #Se deseja plotar a evolucao do erro\n",
    "                        import matplotlib.pyplot as plt\n",
    "                        plt.plot(all_losses)\n",
    "                        plt.show()\n",
    "                    return melhores_pesos,all_losses\n",
    "            \n",
    "        print(\"Treinamento encerrado em {} epocas\".format(epoch))\n",
    "        if plot:       \n",
    "            import matplotlib.pyplot as plt\n",
    "            plt.plot(all_losses)\n",
    "            plt.show()\n",
    "        return melhores_pesos,all_losses\n",
    "\n",
    "    def predict(self,X,melhores_pesos):\n",
    "        #Retorna melhores pesos\n",
    "        self.W1 = melhores_pesos['W1']\n",
    "        self.b1 = melhores_pesos['b1']\n",
    "        self.W2 = melhores_pesos['W2']\n",
    "        self.b2 = melhores_pesos['b2']\n",
    "        z1,a1,z2,output = self.feedforward(X)\n",
    "        return output\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/home/fernando.favoretti/src/personal/mixture_of_experts/utils.py'>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import utils\n",
    "reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============\n",
      "Tamanho total 100\n",
      "Tamanho treino 50\n",
      "Tamanho teste 30\n",
      "Tamanho validacao 20\n",
      "==============\n"
     ]
    }
   ],
   "source": [
    "X, y = datasets.make_moons(100, noise=0.10)\n",
    "X_train,y_train,X_test,y_test,X_val,y_val = utils.treino_teste_validacao(X,y, 0.5, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable initialization\n",
    "max_epocas=1000\n",
    "alpha=0.1 #Setting learning rate\n",
    "ne = X.shape[1] #numero de features no dataset\n",
    "nh = 3 #numero neuronios hidden\n",
    "ns = 1 #numero neuronios saida\n",
    "ep =Expert(ne,nh,ns,g_h='sigmoid',g_o='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinamento encerrado por aumentos consecutivos no erro de validacao, epocas 171\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "melhores_pesos,all_losses = ep.train(max_epocas, alpha, X_train, y_train, X_val, y_val, 5, plot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
