{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import pandas as pd\n",
    "import expert_factory\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============\n",
      "Tamanho total 990\n",
      "Tamanho treino 693\n",
      "Tamanho teste 198\n",
      "Tamanho validacao 99\n",
      "==============\n"
     ]
    }
   ],
   "source": [
    "#Lendo o dadoa\n",
    "df = pd.read_csv('data/treinamento-1.txt', header=None)\n",
    "num_lags = 10\n",
    "\n",
    "#criando Lag\n",
    "lagged_data = utils.create_lag(df, num_lags)\n",
    "lagged_data = lagged_data.reset_index(drop=True)\n",
    "\n",
    "X = lagged_data.drop(['y'],axis=1)\n",
    "y = lagged_data['y']\n",
    "\n",
    "#Criando conjunto de dados\n",
    "fracao_dados_para_treino = 0.7\n",
    "fracao_dados_para_teste = 0.2\n",
    "X_train,y_train,X_test,y_test,X_val,y_val = utils.treino_teste_validacao(X,y, frac_train=fracao_dados_para_treino, frac_test=fracao_dados_para_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vamos comecar com experts iguais\n",
    "exp_ne= X_train.shape[1]\n",
    "exp_nh= 3\n",
    "exp_ns= 1\n",
    "num_experts = 2\n",
    "all_experts = []\n",
    "for _ in range(num_experts):\n",
    "    exp = expert_factory.Expert(exp_ne,exp_nh,exp_ns,g_h='sigmoid',g_o='sigmoid')\n",
    "    all_experts.append(exp)\n",
    "    \n",
    "gating_ne = X_train.shape[1]\n",
    "gating_nh = 3\n",
    "gating_ns = num_experts\n",
    "gating_network = expert_factory.Expert(gating_ne,gating_nh,gating_ns, g_h='sigmoid', g_o='softmax')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = 0\n",
    "old_likelihood = -np.inf\n",
    "iters = 0\n",
    "max_iters = 10\n",
    "matriz_covariancia = np.identity(nExperts)\n",
    "while abs(likelihood-old_likelihood) > 1e-3 and iters < max_iters:\n",
    "    iters += 1\n",
    "    #calcula a saida para cada rede\n",
    "    #A funcao retorna 4 varaiveis, queremos apenas a ultima que representa o output (por isso o [-1])\n",
    "    output_gating = gating_network.feedforward(X_train)[-1]\n",
    "    output_experts = np.matrix([np.ravel(expert.feedforward(X_train)[-1]).tolist() for expert in all_experts]).T\n",
    "    \n",
    "    #Agora que temos a saida comecamos com a funcao de EM\n",
    "    \n",
    "    #Passo E (Expectation)\n",
    "    #Com os parametros atuais calculamos calculamos a 'expectation' posterior para cada expert\n",
    "    old_likelihood = likelihood\n",
    "    likelihood_train,haux_train = calcula_verossimilhanca(num_experts, y_train, output_experts, output_gating, matriz_covariancia)\n",
    "    \n",
    "    #likelihood_val,haux_val = calcula_verossimilhanca(num_experts, y_train, output_experts, output_gating, matriz_covariancia)\n",
    "    \n",
    "    #h = haux./(sum(haux,2)*ones(1,m));\n",
    "    h = np.divide(haux_train, np.sum(haux_train,axis=1))\n",
    "    \n",
    "    #Passo M (Maximizacao)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import sys\n",
    "\n",
    "#import Perceptron_Regressor\n",
    "#import Utilities\n",
    "\n",
    "import importlib\n",
    "# importlib.reload(Perceptron_Regressor)\n",
    "# importlib.reload(Utilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcula_verossimilhanca(num_experts, y_true, output_experts, output_gating, matriz_covariancia):\n",
    "    all_py = []\n",
    "    for expert in range(num_experts):\n",
    "        row = []\n",
    "        for index,y in enumerate(y_true):\n",
    "            #calcula a diff entre o real e o que o cada expert previu\n",
    "            diff = y - output_experts[index,expert]\n",
    "            #Py(j,i)=exp(-diff*diff'/(2*var(i)));   \n",
    "            py = np.exp(np.dot(-diff, diff.T) / (2 * matriz_covariancia[expert,expert]))\n",
    "            row.append(py)\n",
    "        all_py.append(row)\n",
    "    \n",
    "    all_py = np.matrix(all_py).T\n",
    "    # Likelihood= sum(log(sum(Yg.*Py,2)));\n",
    "    #haux = Yg.*Py;\n",
    "    haux = np.multiply(output_gating, all_py)\n",
    "    likelihood = np.sum(np.log(np.sum(aux,axis=1)))\n",
    "    return likelihood,haux\n",
    "        \n",
    "           \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_likelihood(d, y_experts, y_g, covar_matrix):\n",
    "    #list with the probablities of all errors from each expert to each line of input\n",
    "    py_matrix = []\n",
    "    #iterate over the experts\n",
    "    for exp in range(y_experts[0].shape[1]):\n",
    "        py_row = []\n",
    "        #for each expert, calculate the individual py (sum of logs of final output - the gating output multiplied by the corresponding expert output)\n",
    "        for inst, value in enumerate(d):\n",
    "            #diff is the error of the final output\n",
    "            diff = value-y_experts[inst,exp]\n",
    "            py = np.exp(-np.dot(diff, diff.T) / np.multiply(2, covar_matrix[exp,exp]))\n",
    "            py_row += [py[0,0]]\n",
    "        py_matrix += [py_row]\n",
    "    \n",
    "    py_matrix = np.matrix(py_matrix).T\n",
    "    h_aux = np.multiply(y_g, py_matrix)\n",
    "    likelihood = np.sum(np.log(np.sum(h_aux, axis=1)))\n",
    "    \n",
    "    return likelihood, h_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#util = Utilities.Utilities()\n",
    "\n",
    "# def calc_likelihood(d, y_experts, y_g, covar_matrix):\n",
    "#     #create the matrix with the errors of each expert to each instance\n",
    "#     diff = d-y_experts\n",
    "    \n",
    "#     #create the auxiliar matrix that computes the squared error for each expert,\n",
    "#     # multiplied by the covariance matrix,\n",
    "#     # Note: in this case we use the Identity for the covariance matrix\n",
    "#     expert_error = np.sum(np.multiply(covar_matrix, np.dot(diff.T, diff)), axis=0)\n",
    "\n",
    "#     # calculates py as the prior probability multiplied by the exp \n",
    "#     # of the expert_error multiplied by -0.5\n",
    "#     py = np.multiply(np.exp(np.multiply(expert_error, -0.5)), y_g)\n",
    "\n",
    "#     #calculates the final likelihood, computing the sum for each instance of the logs of py\n",
    "#     ll = -np.sum(np.log(py))\n",
    "    \n",
    "#     return ll, py\n",
    "\n",
    "def calc_2norm(m):\n",
    "    return np.sqrt(np.sum(np.multiply(m,m)))\n",
    "\n",
    "def maximize_gating(gating_net, X_train, h, max_it = 1e4, min_norm = 1e-5, X_valid=None, d_valid=None, use_fit=False):\n",
    "    if use_fit:\n",
    "        gating_net.fit(X=X_train, d=h, valid_data=X_valid, valid_d=d_valid, verbose=False)\n",
    "    else:\n",
    "        norm_grad = float(\"inf\")\n",
    "        it = 0\n",
    "\n",
    "        while norm_grad > min_norm and it < max_it:\n",
    "            print(it, norm_grad)\n",
    "            #calculate the descent gradient for h\n",
    "            djdw1, djdw2 = gating_net.calculate_gradient(X=X_train, d=h)\n",
    "            #compute the right leraning rate\n",
    "            learn_rate = gating_net.calculate_bisection(X=X_train, d=h, djdw1=djdw1, djdw2=djdw2)\n",
    "            #learn_rate=0.1\n",
    "            #update the gating network wheights\n",
    "            gating_net.w1, gating_net.w2 = gating_net.update_weights(learning_rate=learn_rate, djdw1=djdw1, djdw2=djdw2,\n",
    "                                                                     w1=gating_net.w1, w2=gating_net.w2)\n",
    "            it+=1\n",
    "            norm_grad = calc_2norm(np.append(djdw1.ravel(), djdw2.ravel(), axis=1))\n",
    "\n",
    "def maximize_expert(expert_net, X_train, h, d_train, covar_matrix=None, max_it = 1e4, min_norm = 1e-5, X_valid=None, d_valid=None, use_fit=False):\n",
    "    if use_fit:\n",
    "        expert_net.fit(X=X_train, d=d_train, valid_data=X_valid, valid_d=d_valid, side_factor=h, verbose=False)\n",
    "    else:\n",
    "        norm_grad = float(\"inf\")\n",
    "        it = 0\n",
    "\n",
    "        #print(\"expert start new\")\n",
    "        while norm_grad > min_norm and it < max_it:\n",
    "            #calculate the descent gradient for h\n",
    "            #print(\"expert start\")\n",
    "            djdw1, djdw2 = gating_net.calculate_gradient(X=X_train, d=d_train, side_factor=h)\n",
    "            #print(\"grad\")\n",
    "            #compute the right leraning rate\n",
    "            learn_rate = gating_net.calculate_bisection(X=X_train, d=d_train, djdw1=djdw1, djdw2=djdw2, side_factor=h)\n",
    "            #learn_rate=0.1\n",
    "            #print(\"alfa\")\n",
    "            #update the gating network wheights\n",
    "            gating_net.w1, gating_net.w2 = gating_net.update_weights(learning_rate=learn_rate, djdw1=djdw1, djdw2=djdw2,\n",
    "                                                                     w1=gating_net.w1, w2=gating_net.w2)\n",
    "\n",
    "            it+=1\n",
    "            norm_grad = calc_2norm(np.append(djdw1.ravel(), djdw2.ravel(), axis=1))\n",
    "\n",
    "            #print(\"weights\")\n",
    "\n",
    "def calc_final_pred(X, gating_net, experts_list):\n",
    "    y_g = gating_net.forward(X)\n",
    "\n",
    "    #y_e = []\n",
    "    #for exp in experts_list:\n",
    "    #    y_e +=[exp.forward(X).T[0]]\n",
    "    #    print()\n",
    "    #print(y_e)\n",
    "    #y_e =np.matrix(y_e).T\n",
    "    y_e = np.matrix([np.array(exp.forward(X).T.tolist()[0]) for exp in experts_list]).T\n",
    "\n",
    "    return np.sum(np.multiply(y_e, y_g), axis=1)\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    # In[ ]:\n",
    "    input_path = r\"input\\treinamento-1.txt\"\n",
    "\n",
    "    input_data=pd.read_csv(open(input_path, \"r\"), header=None)\n",
    "    input_data.columns = [\"time_series\"]\n",
    "    input_data.head()\n",
    "\n",
    "\n",
    "    # In[17]:\n",
    "\n",
    "\n",
    "    lagged_data = util.create_lags(input_data, n=20)\n",
    "\n",
    "    #util.to_excel(lagged_data, \"time_series_with_lag.xlsx\")\n",
    "\n",
    "\n",
    "    # In[18]:\n",
    "\n",
    "\n",
    "    correlations = lagged_data.corr()\n",
    "\n",
    "    #util.to_excel(correlations, \"correlations.xlsx\")\n",
    "\n",
    "\n",
    "    # In[19]:\n",
    "\n",
    "\n",
    "    # CRIA OS INPUTS\n",
    "    max_lags = 5\n",
    "\n",
    "    lagged_data_ = lagged_data[[\"time_series\"] + [\"time_series_lag_{}\".format(i) for i in range(1, max_lags+1)]].dropna()\n",
    "    test, train = util.get_simple_sample(lagged_data_, 0.7)\n",
    "    valid, test = util.get_simple_sample(test, 0.5)\n",
    "\n",
    "    X_train= train[[\"time_series_lag_{}\".format(i) for i in range(1, max_lags+1)]]\n",
    "    X_train[\"bias\"] = 1 # adicionando bias\n",
    "    d_train = train[[\"time_series\"]]\n",
    "\n",
    "    X_test = test[[\"time_series_lag_{}\".format(i) for i in range(1, max_lags+1)]]\n",
    "    X_test[\"bias\"] = 1 # adicionando bias\n",
    "    d_test = test[[\"time_series\"]]\n",
    "\n",
    "    X_valid = valid[[\"time_series_lag_{}\".format(i) for i in range(1, max_lags+1)]]\n",
    "    X_valid[\"bias\"] = 1 # adicionando bias\n",
    "    d_valid = valid[[\"time_series\"]]\n",
    "\n",
    "    nInp = len(X_train.loc[0])\n",
    "    nOut = len(d_train.loc[0])\n",
    "    nHid_gat = 3\n",
    "    nHid_exp = 3\n",
    "    nExperts = 4\n",
    "\n",
    "    #creates the gating network\n",
    "    gating_net = Perceptron_Regressor.MLP(nInp=nInp, nHid=nHid_gat, nOut=nExperts,\n",
    "                                          fFunc=\"sigmoid\", gFunc=\"softmax\",\n",
    "                                          cost_func=\"entropy\")\n",
    "\n",
    "    #creates the expert networks list\n",
    "    experts_list = []\n",
    "    for i in range(nExperts):\n",
    "        expert = Perceptron_Regressor.MLP(nInp=nInp, nHid=nHid_gat, nOut=nOut,\n",
    "                                          fFunc=\"sigmoid\", gFunc=\"sigmoid\",\n",
    "                                          cost_func=\"mse\")\n",
    "        \n",
    "        experts_list+=[expert]\n",
    "\n",
    "\n",
    "    likelihood = 0\n",
    "    likelihood_prev = -float(\"inf\")\n",
    "    max_iterations = 1000\n",
    "    min_ll_gain = 1e-3\n",
    "    covar_matrix = np.identity(nExperts)\n",
    "\n",
    "    #loop to execute the Expectation Maximization algorithm\n",
    "    it = 0\n",
    "    while it < max_iterations and abs(likelihood-likelihood_prev) > min_ll_gain:\n",
    "    #     st_time = time.time()\n",
    "        it+=1\n",
    "        #calculates the outputs of each network\n",
    "        y_g = gating_net.forward(X_train)\n",
    "        #y_experts = np.matrix([exp.forward(X_train).T[0] for exp in experts_list]).T\n",
    "        y_experts = np.matrix([np.array(exp.forward(X_train).T.tolist()[0]) for exp in experts_list]).T\n",
    "        \n",
    "        y_g_valid = gating_net.forward(X_valid)\n",
    "        #y_experts_valid = np.matrix([exp.forward(X_valid).T[0] for exp in experts_list]).T\n",
    "        y_experts_valid = np.matrix([np.array(exp.forward(X_valid).T.tolist()[0]) for exp in experts_list]).T\n",
    "        \n",
    "        #E step - Expectation\n",
    "        # calculates the matrix h of posterior expectations for each expert\n",
    "        likelihood_prev = likelihood\n",
    "        likelihood, h_aux = calc_likelihood(d=np.matrix(d_train), y_experts=y_experts,\n",
    "                                            y_g=y_g, covar_matrix=covar_matrix)\n",
    "        likelihood_valid, h_aux_valid = calc_likelihood(d=np.matrix(d_valid), y_experts=y_experts_valid,\n",
    "                                            y_g=y_g_valid, covar_matrix=covar_matrix)\n",
    "    #     print(\"Likelihood time =\", time.time()-st_time)\n",
    "        \n",
    "    #     st_time = time.time()\n",
    "        #computes the h (posteriori likelihood) dividing elementwise the h_aux\n",
    "        # by the sum of all elements of the matrix \n",
    "        h = np.divide(h_aux, np.sum(h_aux, axis=1))\n",
    "        h_valid = np.divide(h_aux_valid, np.sum(h_aux_valid, axis=1))\n",
    "        \n",
    "        #M step - Maximization\n",
    "        # minimize the cost function for gating and expert networks (maximize the ouputs)\n",
    "        #First - maximize gating network (calulate the descend gradient for the error to h)\n",
    "        maximize_gating(gating_net=gating_net, X_train=X_train, h=h,\n",
    "                        X_valid=X_valid, d_valid=d_valid,use_fit=True)\n",
    "    #     print(\"Maximixing Gating time =\", time.time()-st_time)\n",
    "        \n",
    "        #then maximize each of the experts\n",
    "        for k, expert in enumerate(experts_list):\n",
    "    #         st_time = time.time()\n",
    "            #compute the expert responsability in the error for each instance\n",
    "            #expert_responsability = np.multiply(d_train, np.divide(np.sum(h, axis=0)[0,k], covar_matrix[k,k]))        \n",
    "            maximize_expert(expert_net=expert, X_train=X_train, h=h[:,k],\n",
    "                            d_train=d_train, covar_matrix=covar_matrix,\n",
    "                            X_valid=X_valid, d_valid=d_valid,use_fit=True)\n",
    "    #         print(\"\\t\\tMaximazing Expert\",k,\"time =\", time.time()-st_time)\n",
    "            \n",
    "        y_pred = calc_final_pred(X=X_train, gating_net=gating_net, experts_list=experts_list)\n",
    "        mse = util.get_mse(y_pred, d_train)\n",
    "        print(it, \"\\t\", likelihood, \"\\t\", mse)\n",
    "    print(\"y_pred:\\n\", y_pred)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
