{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import expert_factory\n",
    "importlib.reload(expert_factory)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcula_verossimilhanca(num_experts, y_true, output_experts, output_gating):\n",
    "    py = np.zeros(shape=(len(y_true),num_experts))\n",
    "    for expert in range(0,num_experts):\n",
    "        for index,y in enumerate(y_true):\n",
    "            #calcula a diff entre o real e o que o cada expert previu\n",
    "            #diff = Ytr(j,:)-Yaux(j,:);\n",
    "            diff = y - output_experts[index,expert]\n",
    "            #Py(j,i)=exp(-diff*diff'/(2*var(i)));   \n",
    "            py[index,expert] = np.exp(-np.dot(diff, diff.T) / (2))\n",
    "    # Likelihood= sum(log(sum(Yg.*Py,2)));\n",
    "    #haux = Yg.*Py;\n",
    "    haux = np.multiply(output_gating, py)\n",
    "    likelihood = np.sum(np.log(np.sum(haux,axis=1)))\n",
    "    return likelihood,haux       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_final(X, gating_network, all_experts):\n",
    "    #Calcula saida do gating\n",
    "    gating_output = gating_network.feedforward(X)[-1]\n",
    "    experts_outputs = []\n",
    "    #calcula saida do experts\n",
    "    for exp_net in all_experts:\n",
    "        experts_outputs.append(exp_net.feedforward(X)[-1].tolist())\n",
    "    #retorna o melhor expert como saida\n",
    "    final_output = []\n",
    "    for index_gate, result in enumerate(np.argmax(gating_output,axis=1)):\n",
    "        final_output.append(experts_outputs[result][index_gate])\n",
    "    return final_output\n",
    "        \n",
    "\n",
    "def maximiza_gating(gating_network,max_epocas_gating, alpha_gating, X, y, X_val, y_val,h):\n",
    "    gating_network.train(max_epocas_gating,\n",
    "                         alpha_gating,\n",
    "                         X, y,\n",
    "                         X_val, y_val,\n",
    "                         numero_max_erro_val=10,\n",
    "                         h_tipo='gat',\n",
    "                         h=h,\n",
    "                         plot=False)\n",
    "    \n",
    "def maximiza_expert(expert_network,max_epocas_expert,alpha_expert, X, y, X_val, y_val,h):\n",
    "    expert_network.train(max_epocas_expert,\n",
    "                         alpha_expert,\n",
    "                         X, y,\n",
    "                         X_val, y_val,\n",
    "                         numero_max_erro_val=10,\n",
    "                         h_tipo='exp',\n",
    "                         h=h,\n",
    "                         plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============\n",
      "Tamanho total 985\n",
      "Tamanho treino 689\n",
      "Tamanho teste 197\n",
      "Tamanho validacao 99\n",
      "==============\n"
     ]
    }
   ],
   "source": [
    "#Lendo o dadoa\n",
    "df = pd.read_csv('data/treinamento-1.txt', header=None)\n",
    "\n",
    "#normalizando o dado\n",
    "df = utils.normalize_data(df)\n",
    "num_lags = 15\n",
    "\n",
    "#criando Lag\n",
    "lagged_data = utils.create_lag(df, num_lags)\n",
    "lagged_data = lagged_data.reset_index(drop=True)\n",
    "\n",
    "X = lagged_data.drop(['y'],axis=1)\n",
    "y = lagged_data['y']\n",
    "\n",
    "#Criando conjunto de dados\n",
    "fracao_dados_para_treino = 0.7\n",
    "fracao_dados_para_teste = 0.2\n",
    "X_train,y_train,X_test,y_test,X_val,y_val = utils.treino_teste_validacao(X,y, frac_train=fracao_dados_para_treino, frac_test=fracao_dados_para_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_experts = 4\n",
    "all_ne = X_train.shape[1]\n",
    "## Vamos criar alguns experts\n",
    "all_experts = []\n",
    "exp1 = expert_factory.Expert(ne=all_ne,nh=5,ns=1,g_h='linear',g_o='sigmoid')\n",
    "exp2 = expert_factory.Expert(ne=all_ne,nh=3,ns=1,g_h='linear',g_o='linear')\n",
    "exp3 = expert_factory.Expert(ne=all_ne,nh=3,ns=1,g_h='tan_h',g_o='sigmoid')\n",
    "exp4 = expert_factory.Expert(ne=all_ne,nh=3,ns=1,g_h='sigmoid',g_o='sigmoid')\n",
    "\n",
    "all_experts.append(exp1)\n",
    "all_experts.append(exp2)\n",
    "all_experts.append(exp3)\n",
    "all_experts.append(exp4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando rede gating   \n",
    "gating_ne = X_train.shape[1]\n",
    "gating_nh = 5\n",
    "gating_ns = num_experts\n",
    "gating_network = expert_factory.Expert(gating_ne,gating_nh,gating_ns, g_h='sigmoid', g_o='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4671.98980651\n",
      "Treinamento encerrado em 1 epocas\n",
      "Treinamento encerrado em 1 epocas\n",
      "Treinamento encerrado em 1 epocas\n",
      "Treinamento encerrado em 1 epocas\n",
      "Treinamento encerrado em 1 epocas\n",
      "[[ 0.00086317  0.00012368  0.00011401  0.00033113]\n",
      " [ 0.00086446  0.00012326  0.00011249  0.00033078]\n",
      " [ 0.00088087  0.0001237   0.00011257  0.00033535]\n",
      " ..., \n",
      " [ 0.00087629  0.00012452  0.00011423  0.00033562]\n",
      " [ 0.00090632  0.00012533  0.00011491  0.00034311]\n",
      " [ 0.0008946   0.00012526  0.00011489  0.00034133]]\n",
      "0.346537204953\n",
      "-4695.07727873\n",
      "Treinamento encerrado em 1 epocas\n",
      "Treinamento encerrado em 1 epocas\n",
      "Treinamento encerrado em 1 epocas\n",
      "Treinamento encerrado em 1 epocas\n",
      "Treinamento encerrado em 1 epocas\n",
      "[[ 0.00078739  0.00014389  0.00013204  0.00037044]\n",
      " [ 0.00078868  0.0001434   0.00013028  0.00037006]\n",
      " [ 0.00080292  0.00014391  0.00013037  0.00037512]\n",
      " ..., \n",
      " [ 0.00079852  0.00014487  0.00013229  0.0003754 ]\n",
      " [ 0.00082452  0.00014581  0.00013307  0.00038368]\n",
      " [ 0.00081432  0.00014573  0.00013305  0.00038172]]\n",
      "0.346537204953\n",
      "-4705.45652985\n",
      "Treinamento encerrado em 1 epocas\n",
      "Treinamento encerrado em 1 epocas\n",
      "Treinamento encerrado em 1 epocas\n",
      "Treinamento encerrado em 1 epocas\n",
      "Treinamento encerrado em 1 epocas\n",
      "[[ 0.000721    0.00016352  0.00014918  0.00040155]\n",
      " [ 0.00072228  0.00016297  0.0001472   0.00040114]\n",
      " [ 0.00073473  0.00016354  0.0001473   0.00040656]\n",
      " ..., \n",
      " [ 0.00073052  0.00016464  0.00014947  0.00040684]\n",
      " [ 0.00075319  0.0001657   0.00015035  0.00041568]\n",
      " [ 0.00074425  0.00016562  0.00015032  0.00041361]]\n",
      "0.346537204953\n",
      "-4715.49626023\n",
      "Treinamento encerrado em 1 epocas\n",
      "Treinamento encerrado em 1 epocas\n",
      "Treinamento encerrado em 1 epocas\n",
      "Treinamento encerrado em 1 epocas\n",
      "Treinamento encerrado em 1 epocas\n",
      "[[ 0.00066681  0.0001822   0.00016497  0.00042254]\n",
      " [ 0.00066807  0.00018159  0.00016278  0.00042212]\n",
      " [ 0.00067911  0.00018223  0.00016288  0.00042773]\n",
      " ..., \n",
      " [ 0.00067507  0.00018345  0.00016528  0.000428  ]\n",
      " [ 0.00069513  0.00018463  0.00016624  0.00043713]\n",
      " [ 0.00068718  0.00018454  0.00016622  0.000435  ]]\n",
      "0.346537204953\n",
      "-4725.39346653\n",
      "Treinamento encerrado em 1 epocas\n",
      "Treinamento encerrado em 1 epocas\n",
      "Treinamento encerrado em 1 epocas\n",
      "Treinamento encerrado em 1 epocas\n",
      "Treinamento encerrado em 1 epocas\n",
      "[[ 0.00062237  0.00020034  0.00017966  0.00043524]\n",
      " [ 0.00062361  0.00019966  0.00017727  0.00043483]\n",
      " [ 0.00063353  0.00020037  0.00017738  0.0004405 ]\n",
      " ..., \n",
      " [ 0.00062963  0.00020171  0.00017999  0.00044075]\n",
      " [ 0.00064762  0.00020301  0.00018102  0.00044995]\n",
      " [ 0.00064046  0.0002029   0.000181    0.00044783]]\n",
      "0.346537204953\n",
      "-4735.30511838\n",
      "Treinamento encerrado em 1 epocas\n",
      "Treinamento encerrado em 1 epocas\n",
      "Treinamento encerrado em 1 epocas\n",
      "Treinamento encerrado em 1 epocas\n",
      "Treinamento encerrado em 1 epocas\n",
      "[[ 0.00058542  0.00021822  0.00019342  0.00044151]\n",
      " [ 0.00058664  0.00021749  0.00019085  0.00044111]\n",
      " [ 0.00059565  0.00021826  0.00019096  0.00044674]\n",
      " ..., \n",
      " [ 0.00059189  0.00021972  0.00019376  0.00044695]\n",
      " [ 0.00060819  0.00022114  0.00019486  0.00045606]\n",
      " [ 0.00060166  0.00022102  0.00019484  0.00045398]]\n",
      "0.346537204953\n",
      "nan\n",
      "Treinamento encerrado em 1 epocas\n",
      "Treinamento encerrado em 1 epocas\n",
      "Treinamento encerrado em 1 epocas\n",
      "Treinamento encerrado em 1 epocas\n",
      "Treinamento encerrado em 1 epocas\n",
      "[[ 0.00055416  0.00023606  0.00020632  0.0004429 ]\n",
      " [ 0.00055536  0.00023527  0.00020359  0.00044252]\n",
      " [ 0.0005636   0.0002361   0.00020369  0.00044805]\n",
      " ..., \n",
      " [ 0.00055996  0.00023768  0.00020668  0.00044822]\n",
      " [ 0.00057485  0.00023921  0.00020783  0.00045711]\n",
      " [ 0.00056887  0.00023909  0.00020782  0.00045512]]\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/favoretti/mestrado/data_mining/clods/mixture_of_experts/expert_factory.py:82: RuntimeWarning: overflow encountered in square\n",
      "  loss = np.square(erro_epoca).mean()\n"
     ]
    }
   ],
   "source": [
    "likelihood = 0\n",
    "old_likelihood = -np.inf\n",
    "iters = 0\n",
    "max_iters = 10\n",
    "max_epocas_gating = 1\n",
    "alpha_gating = 0.1\n",
    "while abs(likelihood-old_likelihood) > 1e-3 and iters < max_iters:\n",
    "    iters += 1\n",
    "    #calcula a saida para cada rede\n",
    "    #A funcao retorna 4 variaveis, queremos apenas a ultima que representa o output (por isso o [-1])\n",
    "    output_gating = gating_network.feedforward(X_train)[-1]\n",
    "    output_experts = np.matrix([np.ravel(expert.feedforward(X_train)[-1]).tolist() for expert in all_experts]).T\n",
    "    #Agora que temos a saida comecamos com a funcao de EM\n",
    "    old_likelihood = likelihood\n",
    "    #Passo E (Expectation)\n",
    "    #Com os parametros atuais calculamos calculamos a 'expectation' posterior para cada expert\n",
    "    likelihood,haux_train = calcula_verossimilhanca(num_experts, y_train, output_experts, output_gating)\n",
    "    print(likelihood)\n",
    "    #likelihood_val,haux_val = calcula_verossimilhanca(num_experts, y_train, output_experts, output_gating, matriz_covariancia)\n",
    "    #h = haux./(sum(haux,2)*ones(1,m));\n",
    "    h = np.divide(haux_train, np.dot(np.sum(haux_train,axis=1).reshape(haux_train.shape[0],1),np.ones((1,num_experts))))\n",
    "    #Passo M (Maximizacao)\n",
    "    maximiza_gating(gating_network,max_epocas_gating, alpha_gating, X_train, y_train, X_val, y_val,h)\n",
    "    #Itera por cada expert o treinando com seu respectivo h\n",
    "    for exp_index, expert in enumerate(all_experts):\n",
    "        output_individual_exp = []\n",
    "        for item in h[:,0]:\n",
    "            output_individual_exp.append([item])\n",
    "        maximiza_expert(expert,max_epocas_gating,alpha_gating, X_train, y_train, X_val, y_val,h=output_individual_exp)\n",
    "    print(output_gating)\n",
    "    \n",
    "    saida_final = output_final(X_train, gating_network, all_experts)\n",
    "    erro = saida_final - y_train \n",
    "    loss = np.square(erro).mean()\n",
    "    print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
