{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import pandas as pd\n",
    "import importlib\n",
    "importlib.reload(expert_factory)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcula_verossimilhanca(num_experts, y_true, output_experts, output_gating):\n",
    "    all_py = []\n",
    "    for expert in range(num_experts):\n",
    "        row = []\n",
    "        for index,y in enumerate(y_true):\n",
    "            #calcula a diff entre o real e o que o cada expert previu\n",
    "            diff = y - output_experts[index,expert]\n",
    "            #Py(j,i)=exp(-diff*diff'/(2*var(i)));   \n",
    "            py = np.exp(np.dot(-diff, diff.T) / (2))\n",
    "            row.append(py)\n",
    "        all_py.append(row)\n",
    "    all_py = np.matrix(all_py).T\n",
    "    # Likelihood= sum(log(sum(Yg.*Py,2)));\n",
    "    #haux = Yg.*Py;\n",
    "    haux = np.multiply(output_gating, all_py)\n",
    "    likelihood = np.sum(np.log(np.sum(haux,axis=1)))\n",
    "    return likelihood,haux       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximiza_gating(gating_network,max_epocas_gating, alpha_gating, X_train, h, X_val, y_val):\n",
    "    gating_network.train(max_epocas_gating, alpha_gating, X_train, h, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============\n",
      "Tamanho total 90\n",
      "Tamanho treino 62\n",
      "Tamanho teste 18\n",
      "Tamanho validacao 10\n",
      "==============\n"
     ]
    }
   ],
   "source": [
    "#Lendo o dadoa\n",
    "df = pd.read_csv('data/treinamento-1.txt', header=None)\n",
    "df = df[:100]\n",
    "num_lags = 10\n",
    "\n",
    "#criando Lag\n",
    "lagged_data = utils.create_lag(df, num_lags)\n",
    "lagged_data = lagged_data.reset_index(drop=True)\n",
    "\n",
    "X = lagged_data.drop(['y'],axis=1)\n",
    "y = lagged_data['y']\n",
    "\n",
    "#Criando conjunto de dados\n",
    "fracao_dados_para_treino = 0.7\n",
    "fracao_dados_para_teste = 0.2\n",
    "X_train,y_train,X_test,y_test,X_val,y_val = utils.treino_teste_validacao(X,y, frac_train=fracao_dados_para_treino, frac_test=fracao_dados_para_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vamos comecar com experts iguais\n",
    "exp_ne= X_train.shape[1]\n",
    "exp_nh= 3\n",
    "exp_ns= 1\n",
    "num_experts = 2\n",
    "all_experts = []\n",
    "for _ in range(num_experts):\n",
    "    exp = expert_factory.Expert(exp_ne,exp_nh,exp_ns,g_h='sigmoid',g_o='sigmoid')\n",
    "    all_experts.append(exp)\n",
    "    \n",
    "gating_ne = X_train.shape[1]\n",
    "gating_nh = 3\n",
    "gating_ns = num_experts\n",
    "gating_network = expert_factory.Expert(gating_ne,gating_nh,gating_ns, g_h='sigmoid', g_o='softmax')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===\n",
      "[[0.0060741  0.01659024]\n",
      " [0.00390115 0.01000475]\n",
      " [0.00357578 0.00736063]\n",
      " [0.00331343 0.00617981]\n",
      " [0.00330122 0.00713826]\n",
      " [0.00303783 0.00531731]\n",
      " [0.00258021 0.00476554]\n",
      " [0.00295085 0.00610611]\n",
      " [0.00251052 0.00464868]\n",
      " [0.00363587 0.00726057]\n",
      " [0.00311411 0.00674201]\n",
      " [0.00561449 0.01379652]\n",
      " [0.00372855 0.00816593]\n",
      " [0.00560624 0.01498093]\n",
      " [0.00387965 0.01038885]\n",
      " [0.00524258 0.01248936]\n",
      " [0.00369924 0.00956709]\n",
      " [0.00538229 0.01264746]\n",
      " [0.00342947 0.00876838]\n",
      " [0.00546135 0.01268275]\n",
      " [0.00364897 0.00970567]\n",
      " [0.00552214 0.01341765]\n",
      " [0.00381662 0.00968642]\n",
      " [0.00513136 0.01279057]\n",
      " [0.00431511 0.0118688 ]\n",
      " [0.00458765 0.01076118]\n",
      " [0.00459082 0.01236766]\n",
      " [0.0050739  0.01222974]\n",
      " [0.00441385 0.01224728]\n",
      " [0.00534278 0.01268506]\n",
      " [0.00397239 0.011086  ]\n",
      " [0.00514779 0.01227795]\n",
      " [0.00385292 0.00996292]\n",
      " [0.00556411 0.01479405]\n",
      " [0.00386653 0.00943149]\n",
      " [0.00588839 0.01537815]\n",
      " [0.00392257 0.01054497]\n",
      " [0.00580823 0.01457401]\n",
      " [0.00373977 0.00998481]\n",
      " [0.00580649 0.01466715]\n",
      " [0.00375409 0.0098959 ]\n",
      " [0.00550237 0.01354063]\n",
      " [0.00428107 0.0116103 ]\n",
      " [0.00535335 0.01352281]\n",
      " [0.00489849 0.01394953]\n",
      " [0.00506862 0.01302506]\n",
      " [0.0050476  0.01486275]\n",
      " [0.0044746  0.01071912]\n",
      " [0.00568156 0.01712516]\n",
      " [0.00457791 0.01130328]\n",
      " [0.00583961 0.0163088 ]\n",
      " [0.00479    0.01248762]\n",
      " [0.00503238 0.01382691]\n",
      " [0.00516095 0.01340176]\n",
      " [0.00434666 0.01197276]\n",
      " [0.00556481 0.01480495]\n",
      " [0.00383691 0.00965758]\n",
      " [0.00588249 0.01603731]\n",
      " [0.00412719 0.010399  ]\n",
      " [0.00616361 0.01746555]\n",
      " [0.00391407 0.00950056]\n",
      " [0.00581964 0.01535063]]\n",
      "62\n",
      "===\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (62,2) and (62,2) not aligned: 2 (dim 1) != 62 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-9a2b52486784>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdivide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhaux_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhaux_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m#Passo M (Maximizacao)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mmaximiza_gating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgating_network\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_epocas_gating\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha_gating\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-63-a53b827df79e>\u001b[0m in \u001b[0;36mmaximiza_gating\u001b[0;34m(gating_network, max_epocas_gating, alpha_gating, X_train, h, X_val, y_val)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmaximiza_gating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgating_network\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_epocas_gating\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha_gating\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mgating_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epocas_gating\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha_gating\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/src/personal/mixture_of_experts/expert_factory.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, max_epoch, alpha, X, y, X_val, y_val, numero_max_erro_val, plot)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"===\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;31m#backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0merro_epoca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackpropagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0;31m#gera loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mall_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalcula_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merro_epoca\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/personal/mixture_of_experts/expert_factory.py\u001b[0m in \u001b[0;36mbackpropagation\u001b[0;34m(self, X, y, z1, a1, z2, output, alpha)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0merro_epoca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mdelta_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuta_funcao_ativacao\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderivativa\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0md_z2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merro_epoca\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdelta_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0merro_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_z2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mdelta_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuta_funcao_ativacao\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mghidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mderivativa\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0;31m# This promotes 1-D vectors to row vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__rmul__'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (62,2) and (62,2) not aligned: 2 (dim 1) != 62 (dim 0)"
     ]
    }
   ],
   "source": [
    "likelihood = 0\n",
    "old_likelihood = -np.inf\n",
    "iters = 0\n",
    "max_iters = 10\n",
    "max_epocas_gating = 2\n",
    "alpha_gating = 0.5\n",
    "while abs(likelihood-old_likelihood) > 1e-3 and iters < max_iters:\n",
    "    iters += 1\n",
    "    #calcula a saida para cada rede\n",
    "    #A funcao retorna 4 varaiveis, queremos apenas a ultima que representa o output (por isso o [-1])\n",
    "    output_gating = gating_network.feedforward(X_train)[-1]\n",
    "    output_experts = np.matrix([np.ravel(expert.feedforward(X_train)[-1]).tolist() for expert in all_experts]).T\n",
    "    #Agora que temos a saida comecamos com a funcao de EM\n",
    "    \n",
    "    #Passo E (Expectation)\n",
    "    #Com os parametros atuais calculamos calculamos a 'expectation' posterior para cada expert\n",
    "    old_likelihood = likelihood\n",
    "    likelihood_train,haux_train = calcula_verossimilhanca(num_experts, y_train, output_experts, output_gating)\n",
    "    \n",
    "    #likelihood_val,haux_val = calcula_verossimilhanca(num_experts, y_train, output_experts, output_gating, matriz_covariancia)\n",
    "    \n",
    "    #h = haux./(sum(haux,2)*ones(1,m));\n",
    "    h = np.divide(haux_train, np.sum(haux_train,axis=1))\n",
    "    #Passo M (Maximizacao)\n",
    "    maximiza_gating(gating_network,max_epocas_gating, alpha_gating, X_train, h, X_val, y_val)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import sys\n",
    "\n",
    "#import Perceptron_Regressor\n",
    "#import Utilities\n",
    "\n",
    "import importlib\n",
    "importlib.reload(Perceptron_Regressor)\n",
    "# importlib.reload(Utilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_likelihood(d, y_experts, y_g, covar_matrix):\n",
    "    #list with the probablities of all errors from each expert to each line of input\n",
    "    py_matrix = []\n",
    "    #iterate over the experts\n",
    "    for exp in range(y_experts[0].shape[1]):\n",
    "        py_row = []\n",
    "        #for each expert, calculate the individual py (sum of logs of final output - the gating output multiplied by the corresponding expert output)\n",
    "        for inst, value in enumerate(d):\n",
    "            #diff is the error of the final output\n",
    "            diff = value-y_experts[inst,exp]\n",
    "            py = np.exp(-np.dot(diff, diff.T) / np.multiply(2, covar_matrix[exp,exp]))\n",
    "            py_row += [py[0,0]]\n",
    "        py_matrix += [py_row]\n",
    "    \n",
    "    py_matrix = np.matrix(py_matrix).T\n",
    "    h_aux = np.multiply(y_g, py_matrix)\n",
    "    likelihood = np.sum(np.log(np.sum(h_aux, axis=1)))\n",
    "    \n",
    "    return likelihood, h_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#util = Utilities.Utilities()\n",
    "\n",
    "# def calc_likelihood(d, y_experts, y_g, covar_matrix):\n",
    "#     #create the matrix with the errors of each expert to each instance\n",
    "#     diff = d-y_experts\n",
    "    \n",
    "#     #create the auxiliar matrix that computes the squared error for each expert,\n",
    "#     # multiplied by the covariance matrix,\n",
    "#     # Note: in this case we use the Identity for the covariance matrix\n",
    "#     expert_error = np.sum(np.multiply(covar_matrix, np.dot(diff.T, diff)), axis=0)\n",
    "\n",
    "#     # calculates py as the prior probability multiplied by the exp \n",
    "#     # of the expert_error multiplied by -0.5\n",
    "#     py = np.multiply(np.exp(np.multiply(expert_error, -0.5)), y_g)\n",
    "\n",
    "#     #calculates the final likelihood, computing the sum for each instance of the logs of py\n",
    "#     ll = -np.sum(np.log(py))\n",
    "    \n",
    "#     return ll, py\n",
    "\n",
    "def calc_2norm(m):\n",
    "    return np.sqrt(np.sum(np.multiply(m,m)))\n",
    "\n",
    "def maximize_gating(gating_net, X_train, h, max_it = 1e4, min_norm = 1e-5, X_valid=None, d_valid=None, use_fit=False):\n",
    "    if use_fit:\n",
    "        gating_net.fit(X=X_train, d=h, valid_data=X_valid, valid_d=d_valid, verbose=False)\n",
    "    else:\n",
    "        norm_grad = float(\"inf\")\n",
    "        it = 0\n",
    "\n",
    "        while norm_grad > min_norm and it < max_it:\n",
    "            print(it, norm_grad)\n",
    "            #calculate the descent gradient for h\n",
    "            djdw1, djdw2 = gating_net.calculate_gradient(X=X_train, d=h)\n",
    "            #compute the right leraning rate\n",
    "            learn_rate = gating_net.calculate_bisection(X=X_train, d=h, djdw1=djdw1, djdw2=djdw2)\n",
    "            #learn_rate=0.1\n",
    "            #update the gating network wheights\n",
    "            gating_net.w1, gating_net.w2 = gating_net.update_weights(learning_rate=learn_rate, djdw1=djdw1, djdw2=djdw2,\n",
    "                                                                     w1=gating_net.w1, w2=gating_net.w2)\n",
    "            it+=1\n",
    "            norm_grad = calc_2norm(np.append(djdw1.ravel(), djdw2.ravel(), axis=1))\n",
    "\n",
    "def maximize_expert(expert_net, X_train, h, d_train, covar_matrix=None, max_it = 1e4, min_norm = 1e-5, X_valid=None, d_valid=None, use_fit=False):\n",
    "    if use_fit:\n",
    "        expert_net.fit(X=X_train, d=d_train, valid_data=X_valid, valid_d=d_valid, side_factor=h, verbose=False)\n",
    "    else:\n",
    "        norm_grad = float(\"inf\")\n",
    "        it = 0\n",
    "\n",
    "        #print(\"expert start new\")\n",
    "        while norm_grad > min_norm and it < max_it:\n",
    "            #calculate the descent gradient for h\n",
    "            #print(\"expert start\")\n",
    "            djdw1, djdw2 = gating_net.calculate_gradient(X=X_train, d=d_train, side_factor=h)\n",
    "            #print(\"grad\")\n",
    "            #compute the right leraning rate\n",
    "            learn_rate = gating_net.calculate_bisection(X=X_train, d=d_train, djdw1=djdw1, djdw2=djdw2, side_factor=h)\n",
    "            #learn_rate=0.1\n",
    "            #print(\"alfa\")\n",
    "            #update the gating network wheights\n",
    "            gating_net.w1, gating_net.w2 = gating_net.update_weights(learning_rate=learn_rate, djdw1=djdw1, djdw2=djdw2,\n",
    "                                                                     w1=gating_net.w1, w2=gating_net.w2)\n",
    "\n",
    "            it+=1\n",
    "            norm_grad = calc_2norm(np.append(djdw1.ravel(), djdw2.ravel(), axis=1))\n",
    "\n",
    "            #print(\"weights\")\n",
    "\n",
    "def calc_final_pred(X, gating_net, experts_list):\n",
    "    y_g = gating_net.forward(X)\n",
    "\n",
    "    #y_e = []\n",
    "    #for exp in experts_list:\n",
    "    #    y_e +=[exp.forward(X).T[0]]\n",
    "    #    print()\n",
    "    #print(y_e)\n",
    "    #y_e =np.matrix(y_e).T\n",
    "    y_e = np.matrix([np.array(exp.forward(X).T.tolist()[0]) for exp in experts_list]).T\n",
    "\n",
    "    return np.sum(np.multiply(y_e, y_g), axis=1)\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    # In[ ]:\n",
    "    input_path = r\"input\\treinamento-1.txt\"\n",
    "\n",
    "    input_data=pd.read_csv(open(input_path, \"r\"), header=None)\n",
    "    input_data.columns = [\"time_series\"]\n",
    "    input_data.head()\n",
    "\n",
    "\n",
    "    # In[17]:\n",
    "\n",
    "\n",
    "    lagged_data = util.create_lags(input_data, n=20)\n",
    "\n",
    "    #util.to_excel(lagged_data, \"time_series_with_lag.xlsx\")\n",
    "\n",
    "\n",
    "    # In[18]:\n",
    "\n",
    "\n",
    "    correlations = lagged_data.corr()\n",
    "\n",
    "    #util.to_excel(correlations, \"correlations.xlsx\")\n",
    "\n",
    "\n",
    "    # In[19]:\n",
    "\n",
    "\n",
    "    # CRIA OS INPUTS\n",
    "    max_lags = 5\n",
    "\n",
    "    lagged_data_ = lagged_data[[\"time_series\"] + [\"time_series_lag_{}\".format(i) for i in range(1, max_lags+1)]].dropna()\n",
    "    test, train = util.get_simple_sample(lagged_data_, 0.7)\n",
    "    valid, test = util.get_simple_sample(test, 0.5)\n",
    "\n",
    "    X_train= train[[\"time_series_lag_{}\".format(i) for i in range(1, max_lags+1)]]\n",
    "    X_train[\"bias\"] = 1 # adicionando bias\n",
    "    d_train = train[[\"time_series\"]]\n",
    "\n",
    "    X_test = test[[\"time_series_lag_{}\".format(i) for i in range(1, max_lags+1)]]\n",
    "    X_test[\"bias\"] = 1 # adicionando bias\n",
    "    d_test = test[[\"time_series\"]]\n",
    "\n",
    "    X_valid = valid[[\"time_series_lag_{}\".format(i) for i in range(1, max_lags+1)]]\n",
    "    X_valid[\"bias\"] = 1 # adicionando bias\n",
    "    d_valid = valid[[\"time_series\"]]\n",
    "\n",
    "    nInp = len(X_train.loc[0])\n",
    "    nOut = len(d_train.loc[0])\n",
    "    nHid_gat = 3\n",
    "    nHid_exp = 3\n",
    "    nExperts = 4\n",
    "\n",
    "    #creates the gating network\n",
    "    gating_net = Perceptron_Regressor.MLP(nInp=nInp, nHid=nHid_gat, nOut=nExperts,\n",
    "                                          fFunc=\"sigmoid\", gFunc=\"softmax\",\n",
    "                                          cost_func=\"entropy\")\n",
    "\n",
    "    #creates the expert networks list\n",
    "    experts_list = []\n",
    "    for i in range(nExperts):\n",
    "        expert = Perceptron_Regressor.MLP(nInp=nInp, nHid=nHid_gat, nOut=nOut,\n",
    "                                          fFunc=\"sigmoid\", gFunc=\"sigmoid\",\n",
    "                                          cost_func=\"mse\")\n",
    "        \n",
    "        experts_list+=[expert]\n",
    "\n",
    "\n",
    "    likelihood = 0\n",
    "    likelihood_prev = -float(\"inf\")\n",
    "    max_iterations = 1000\n",
    "    min_ll_gain = 1e-3\n",
    "    covar_matrix = np.identity(nExperts)\n",
    "\n",
    "    #loop to execute the Expectation Maximization algorithm\n",
    "    it = 0\n",
    "    while it < max_iterations and abs(likelihood-likelihood_prev) > min_ll_gain:\n",
    "    #     st_time = time.time()\n",
    "        it+=1\n",
    "        #calculates the outputs of each network\n",
    "        y_g = gating_net.forward(X_train)\n",
    "        #y_experts = np.matrix([exp.forward(X_train).T[0] for exp in experts_list]).T\n",
    "        y_experts = np.matrix([np.array(exp.forward(X_train).T.tolist()[0]) for exp in experts_list]).T\n",
    "        \n",
    "        y_g_valid = gating_net.forward(X_valid)\n",
    "        #y_experts_valid = np.matrix([exp.forward(X_valid).T[0] for exp in experts_list]).T\n",
    "        y_experts_valid = np.matrix([np.array(exp.forward(X_valid).T.tolist()[0]) for exp in experts_list]).T\n",
    "        \n",
    "        #E step - Expectation\n",
    "        # calculates the matrix h of posterior expectations for each expert\n",
    "        likelihood_prev = likelihood\n",
    "        likelihood, h_aux = calc_likelihood(d=np.matrix(d_train), y_experts=y_experts,\n",
    "                                            y_g=y_g, covar_matrix=covar_matrix)\n",
    "        likelihood_valid, h_aux_valid = calc_likelihood(d=np.matrix(d_valid), y_experts=y_experts_valid,\n",
    "                                            y_g=y_g_valid, covar_matrix=covar_matrix)\n",
    "    #     print(\"Likelihood time =\", time.time()-st_time)\n",
    "        \n",
    "    #     st_time = time.time()\n",
    "        #computes the h (posteriori likelihood) dividing elementwise the h_aux\n",
    "        # by the sum of all elements of the matrix \n",
    "        h = np.divide(h_aux, np.sum(h_aux, axis=1))\n",
    "        h_valid = np.divide(h_aux_valid, np.sum(h_aux_valid, axis=1))\n",
    "        \n",
    "        #M step - Maximization\n",
    "        # minimize the cost function for gating and expert networks (maximize the ouputs)\n",
    "        #First - maximize gating network (calulate the descend gradient for the error to h)\n",
    "        maximize_gating(gating_net=gating_net, X_train=X_train, h=h,\n",
    "                        X_valid=X_valid, d_valid=d_valid,use_fit=True)\n",
    "    #     print(\"Maximixing Gating time =\", time.time()-st_time)\n",
    "        \n",
    "        #then maximize each of the experts\n",
    "        for k, expert in enumerate(experts_list):\n",
    "    #         st_time = time.time()\n",
    "            #compute the expert responsability in the error for each instance\n",
    "            #expert_responsability = np.multiply(d_train, np.divide(np.sum(h, axis=0)[0,k], covar_matrix[k,k]))        \n",
    "            maximize_expert(expert_net=expert, X_train=X_train, h=h[:,k],\n",
    "                            d_train=d_train, covar_matrix=covar_matrix,\n",
    "                            X_valid=X_valid, d_valid=d_valid,use_fit=True)\n",
    "    #         print(\"\\t\\tMaximazing Expert\",k,\"time =\", time.time()-st_time)\n",
    "            \n",
    "        y_pred = calc_final_pred(X=X_train, gating_net=gating_net, experts_list=experts_list)\n",
    "        mse = util.get_mse(y_pred, d_train)\n",
    "        print(it, \"\\t\", likelihood, \"\\t\", mse)\n",
    "    print(\"y_pred:\\n\", y_pred)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
